# Qwen3-Embedding MCP Server with Information Lensing

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![MCP](https://img.shields.io/badge/MCP-Compatible-green.svg)](https://modelcontextprotocol.io)

A high-performance [Model Context Protocol (MCP)](https://modelcontextprotocol.io) server providing state-of-the-art text embeddings using **Qwen3-Embedding-8B** with **Information Lensing** â€” domain-specific embedding transformation for enterprise codebases.

## What is Information Lensing?

Just as gravitational lensing bends light to reveal distant galaxies, **Information Lensing** curves embedding space to reveal hidden semantic structure in code.

Generic embeddings suffer from **semantic collapse** â€” `PaymentService` and `InventoryService` look nearly identical (0.94 cosine similarity) despite having completely different business purposes.

Information Lensing applies three "gravitational lenses" that focus embeddings on different aspects:

| Lens | Focus | Use Case |
|------|-------|----------|
| **structural** | Graph topology, architectural position, connectivity | Finding related modules, dependency analysis |
| **semantic** | Business logic, domain concepts, code meaning | Finding code by functionality |
| **behavioral** | Runtime patterns, state machines, side effects | Finding code by execution behavior |

Reference: Marchewka (2025), "Information Lensing: A Gravitational Approach to Domain-Specific Embedding Transformation"

## Features

- ğŸ”­ **Information Lensing**: Three domain-specific lenses (structural, semantic, behavioral)
- ğŸš€ **State-of-the-Art Quality**: Qwen3-Embedding-8B ranks #1 on MTEB multilingual benchmark
- ğŸŒ **100+ Languages**: Including programming languages (Java, TypeScript, Python, etc.)
- ğŸ“ **Flexible Dimensions**: MRL for custom dimensions (128-4096)
- ğŸ“„ **32K Context**: Process long files up to 32,768 tokens
- ğŸ’» **CPU Optimized**: Designed for high-RAM CPU systems (64GB+ recommended)

## Requirements

- **Python**: 3.10 or higher
- **RAM**: 32GB minimum, 64GB+ recommended
- **Disk**: ~16GB for model weights

## Quick Start

### Installation

```bash
# Clone and setup
git clone https://github.com/NorbertMarchewka/qwen3-embedding-mcp.git
cd qwen3-embedding-mcp
python -m venv .venv
.venv\Scripts\activate  # Windows
pip install -e .
```

### Running

```bash
python -m qwen3_embedding_mcp
```

### Claude Desktop Configuration

```json
{
  "mcpServers": {
    "qwen3-embedding": {
      "command": "C:/path/to/.venv/Scripts/python.exe",
      "args": ["-m", "qwen3_embedding_mcp"]
    }
  }
}
```

## Available Tools

### `embed` â€” Single Document with Lens

Generate embedding for a document using Information Lensing.

```json
{
  "text": "class PaymentService { ... }",
  "lens": "semantic"
}
```

**Parameters:**
- `text` (required): Document content (max 32K tokens)
- `lens` (required): `"structural"`, `"semantic"`, or `"behavioral"`
- `dimension` (optional): Output dimension 128-4096 (default: 4096)

**Returns:** 4096-dimensional embedding focused on the selected aspect.

---

### `embed_triple` â€” All Three Lenses

Generate all three lens embeddings in one call. Use for building the triple-embedded hypergraph.

```json
{
  "text": "class PaymentService { ... }"
}
```

**Returns:**
```json
{
  "structural": { "embedding": [...], "dimensions": 4096 },
  "semantic": { "embedding": [...], "dimensions": 4096 },
  "behavioral": { "embedding": [...], "dimensions": 4096 }
}
```

---

### `batch_embed` â€” Multiple Documents, Same Lens

```json
{
  "texts": ["class A { ... }", "class B { ... }"],
  "lens": "semantic"
}
```

---

### `similarity` â€” Compare Queries to Documents

```json
{
  "queries": ["payment processing"],
  "documents": ["PaymentService.java content...", "InventoryService.java content..."],
  "query_lens": "semantic"
}
```

---

### `model_info` â€” Status and Available Lenses

```json
{}
```

## Domain Instructions (Information Lensing)

The three lenses apply these domain-specific instructions automatically:

### Structural Lens
> Embed the STRUCTURAL TOPOLOGY of code in a directed heterogeneous hypergraph. Focus ONLY on: graph connectivity, centrality measures, community structure, node types (Controller, Service, Repository), edge types (METHOD_CALL, DEPENDENCY_INJECTION), design patterns. Completely IGNORE what the code does - only HOW it's connected.

### Semantic Lens
> Embed the SEMANTIC MEANING of Spring Boot code for CheckItOut. Focus ONLY on: business logic (influencer marketing, campaigns, payments), what this code DOES functionally, algorithms, domain terminology, API contracts. Completely IGNORE structure and runtime - only WHAT it means.

### Behavioral Lens
> Embed the RUNTIME BEHAVIOR of code execution. Focus ONLY on: state machines, error handling, retry logic, circuit breakers, transaction boundaries, async operations, side effects (DB writes, network calls), causal relationships. Completely IGNORE static structure and meaning - only HOW it behaves.

## Usage Example

```
User: Embed this PaymentService code with semantic lens

Claude: [calls embed with lens="semantic"]
Result: 4096D embedding focused on business meaning
```

```
User: Generate all three embeddings for InventoryController

Claude: [calls embed_triple]
Result: structural, semantic, and behavioral embeddings
```

## Configuration

| Variable | Default | Description |
|----------|---------|-------------|
| `QWEN3_EMBEDDING_MODEL_ID` | `Qwen/Qwen3-Embedding-8B` | Model ID |
| `QWEN3_EMBEDDING_DEVICE` | `cpu` | Device: cpu, cuda, mps |
| `QWEN3_EMBEDDING_DEFAULT_DIMENSION` | `4096` | Default embedding dimension |
| `QWEN3_EMBEDDING_LOG_LEVEL` | `INFO` | Logging level |

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MCP Client (Claude)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MCP Server (stdio)                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                   Tool Router                        â”‚   â”‚
â”‚  â”‚  embed | embed_triple | batch_embed | similarity    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                        â”‚                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              Embedding Engine                        â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚   â”‚
â”‚  â”‚  â”‚         Information Lensing Layer           â”‚    â”‚   â”‚
â”‚  â”‚  â”‚  structural | semantic | behavioral         â”‚    â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚   â”‚
â”‚  â”‚                        â”‚                             â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚   â”‚
â”‚  â”‚  â”‚          Qwen3-Embedding-8B                 â”‚    â”‚   â”‚
â”‚  â”‚  â”‚          (sentence-transformers)            â”‚    â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Performance

- **Single embed**: ~200-500ms (CPU)
- **Triple embed**: ~600-1500ms (CPU)
- **Batch of 20**: ~2-4s (CPU)
- **Cold start**: ~2-3 minutes (model loading)

## Related Work

- [Information Lensing Appendix](../GraphTheoryInSystemModeling/appendix_information_lensing.md)
- [Triple 4096D Pipeline](../WorkingNotes/enhanced_graph_pipeline.md)
- [Qwen3-Embedding Paper](https://arxiv.org/abs/2506.05176)

---

Made with â¤ï¸ by [Norbert Marchewka](https://github.com/NorbertMarchewka)
